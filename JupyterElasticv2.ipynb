{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "# Return a response of the top 100 IAMA Reddit posts of all time\n",
    "response = requests.get(\"http://api.reddit.com/r/iama/top/?t=all&limit=100\", \n",
    "                        headers={\"User-Agent\":\"TrackMaven\"})\n",
    "\n",
    "fields = ['title', 'selftext', 'author', 'score', \n",
    "        'ups', 'downs', 'num_comments', 'url', 'created']\n",
    "\n",
    "# Loop through results and add each data dictionary to the ES \"reddit\" index\n",
    "for i, iama in enumerate(response.json()['data']['children']):\n",
    "    content = iama['data']\n",
    "    doc = {}\n",
    "    for field in fields:\n",
    "        doc[field] = content[field]\n",
    "    es.index(index=\"reddit\", doc_type='iama', id=i, body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'selftext': \"**My 6 Questions:**\\n\\n1. How did you enjoy your time working at Reddit?\\n2. Were you expecting to be let go?\\n3. What are you planning to do now?\\n4. What was your favorite AMA?\\n5. Would you come back, if possible?\\n6. Are you planning to take [Campus Society's](http://blog.campussociety.com/an-open-letter-to-victoria-previously-of-reddit-become-victoria-of-campus-society/) Job offer?\\n\\n**Public Contact Information:** @happysquid is her twitter (Thanks /u/crabjuice23 And /u/edjamakated!) &amp; /u/chooter (Thanks /u/alsadius)\\n\\n\\nEdit: The votes dropped from 17K+ to 10K+ in a matter of seconds...what?\\n\\nEdit again: I've lost a total of about 14K votes...Vote fuzzing seems a bit way too much\\n\", 'ups': 126765, 'downs': 0, 'num_comments': 2864, 'url': 'https://www.reddit.com/r/IAmA/comments/3c0iw2/ama_request_victoria_exama_mod/', 'author': 'korantano', 'score': 126765, 'created': 1435973760.0, 'title': '[AMA Request] Victoria, ex-AMA mod'}\n",
      "{'took': 1, 'timed_out': False, 'hits': {'max_score': None, 'hits': [], 'total': 0}, '_shards': {'successful': 5, 'failed': 0, 'total': 5}}\n",
      "100\n",
      "Chris Pratt. AMA. I'm an open book. Come get some!!\n",
      "1\n",
      "I am Barack Obama, President of the United States -- AMA\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "\n",
    "# Fetch a specific result\n",
    "res = es.get(index='reddit', doc_type='iama', id=1)\n",
    "print(res['_source'])\n",
    "\n",
    "# Update the index to be able to query against it\n",
    "es.indices.refresh(index=\"reddit\")\n",
    "\n",
    "# Query for results: nothing will match this author\n",
    "res = es.search(index=\"reddit\", \n",
    "                body={\"query\": {\"match\": {\"author\": \"no results here!\"}}})\n",
    "print(res)\n",
    "\n",
    "# Query for all results (no matching criteria)\n",
    "res = es.search(index=\"reddit\", body={\"query\": {\"match_all\": {}}})\n",
    "print(res['hits']['total'])\n",
    "print(res['hits']['hits'][1]['_source']['title'])\n",
    "\n",
    "# Query based on text appearing in the title\n",
    "# (by default matches across capitalization, pluralization, etc)\n",
    "res = es.search(index=\"reddit\", body={\"query\": {\"match\": {\"title\": \"obama\"}}})\n",
    "print(res['hits']['total'])\n",
    "print(res['hits']['hits'][0]['_source']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Map the fields of a new \"trip\" doc_type\n",
    "mapping = {\n",
    "    \"trip\": {\n",
    "        \"properties\": {\n",
    "            \"duration\": {\"type\": \"integer\"},\n",
    "            \"start_date\": {\"type\": \"string\"},\n",
    "            \"start_station\": {\"type\": \"string\", \"index\": \"not_analyzed\"},\n",
    "            \"start_terminal\": {\"type\": \"integer\"},\n",
    "            \"end_date\": {\"type\": \"string\"},\n",
    "            \"end_station\": {\"type\": \"string\", \"index\": \"not_analyzed\"},\n",
    "            \"end_terminal\": {\"type\": \"integer\"},\n",
    "            \"bike_id\": {\"type\": \"string\"},\n",
    "            \"subscriber\": {\"type\": \"string\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a new \"bikeshare\" index that includes \"trips\" with the above mapping\n",
    "es = Elasticsearch()\n",
    "es.indices.delete(\"bikeshare\")\n",
    "es.indices.create(\"bikeshare\")\n",
    "es.indices.put_mapping(index=\"bikeshare\", doc_type=\"trip\", body=mapping)\n",
    "\n",
    "# Import a CSV file of trip data - this will take quite a while!\n",
    "with open('2010-Q4-cabi-trip-history-data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    header = next(reader) # Skip header row\n",
    "    for id, row in enumerate(reader):\n",
    "        h, m, s = row[0].split()\n",
    "        trip_seconds = int(int(h.replace(\"h\", \"\"))*60*60 + int(int(m.replace(\"min.\", \"\")))*60 + int(int(s.replace(\"sec.\", \"\"))))\n",
    "        content = {\n",
    "            \"duration\": trip_seconds,\n",
    "            \"start_date\": row[1],\n",
    "            \"end_date\": row[2],\n",
    "            \"start_station\": row[3],\n",
    "            \"end_station\": row[4],\n",
    "            \"bike_id\": row[5],\n",
    "            \"member_type\": row[6],\n",
    "        }\n",
    "        es.index(index=\"bikeshare\", doc_type='trip', id=id, body=content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
